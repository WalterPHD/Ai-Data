{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBAYokGCnGrzst+VFQnF4s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalterPHD/Ai-Data/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1"
      ],
      "metadata": {
        "id": "f4lLTb7RN1Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimpleRNN, GRU, LSTM on IMDB"
      ],
      "metadata": {
        "id": "njAwHcpgNlFy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp9iwl2-LgJL",
        "outputId": "9f73e80e-0687-43d2-853a-2bcef38f9b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\n",
            "Training with SimpleRNN...\n",
            "Epoch 1/2\n",
            "313/313 - 35s - 112ms/step - accuracy: 0.6901 - loss: 0.5705 - val_accuracy: 0.7362 - val_loss: 0.5276\n",
            "Epoch 2/2\n",
            "313/313 - 34s - 109ms/step - accuracy: 0.8654 - loss: 0.3243 - val_accuracy: 0.7086 - val_loss: 0.5846\n",
            "\n",
            "Training with GRU...\n",
            "Epoch 1/2\n",
            "313/313 - 98s - 314ms/step - accuracy: 0.7439 - loss: 0.4938 - val_accuracy: 0.8468 - val_loss: 0.3523\n",
            "Epoch 2/2\n",
            "313/313 - 102s - 326ms/step - accuracy: 0.8986 - loss: 0.2598 - val_accuracy: 0.8476 - val_loss: 0.3700\n",
            "\n",
            "Training with LSTM...\n",
            "Epoch 1/2\n",
            "313/313 - 92s - 293ms/step - accuracy: 0.7892 - loss: 0.4444 - val_accuracy: 0.8466 - val_loss: 0.3595\n",
            "Epoch 2/2\n",
            "313/313 - 93s - 298ms/step - accuracy: 0.9075 - loss: 0.2406 - val_accuracy: 0.8106 - val_loss: 0.3978\n",
            "\n",
            "Final Accuracy Comparison:\n",
            "SimpleRNN: 0.7134\n",
            "GRU: 0.8361\n",
            "LSTM: 0.8135\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load IMDB dataset\n",
        "max_features = 20000  # number of words\n",
        "maxlen = 200          # cut reviews after 200 words\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "def build_model(rnn_layer):\n",
        "    model = keras.Sequential([\n",
        "        layers.Embedding(max_features, 128),\n",
        "        rnn_layer,\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Try different recurrent layers\n",
        "for rnn_layer in [\n",
        "    layers.SimpleRNN(64),\n",
        "    layers.GRU(64),\n",
        "    layers.LSTM(64),\n",
        "]:\n",
        "    print(f\"\\nTraining with {rnn_layer.__class__.__name__}...\")\n",
        "    model = build_model(rnn_layer)\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=64,\n",
        "        epochs=2,          # keep small for runtime\n",
        "        validation_split=0.2,\n",
        "        verbose=2\n",
        "    )\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    results[rnn_layer.__class__.__name__] = score[1]\n",
        "\n",
        "print(\"\\nFinal Accuracy Comparison:\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ConvLSTM2D"
      ],
      "metadata": {
        "id": "hBhxIDIlNojT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Conv3D\n",
        "\n",
        "# Example ConvLSTM2D model\n",
        "model = Sequential([\n",
        "    ConvLSTM2D(filters=40, kernel_size=(3, 3), input_shape=(None, 40, 40, 1), padding=\"same\", return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    ConvLSTM2D(filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\")\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "8EgI78WuNqv0",
        "outputId": "1058241b-f74c-4112-cd62-9f0b4ce6f9e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │        \u001b[38;5;34m59,200\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m40\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │           \u001b[38;5;34m160\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m40\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_1 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │       \u001b[38;5;34m115,360\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m40\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │           \u001b[38;5;34m160\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m40\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │         \u001b[38;5;34m1,081\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m1\u001b[0m)                     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">59,200</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,360</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,081</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,961\u001b[0m (687.35 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,961</span> (687.35 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,801\u001b[0m (686.72 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,801</span> (686.72 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2"
      ],
      "metadata": {
        "id": "jZnGpiP-NzC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "max_features = 10000  # Number of words to keep\n",
        "maxlen = 500          # Cut texts after 500 words\n",
        "\n",
        "# Load Reuters dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.reuters.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences so all have same length\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrnROlPN6-W",
        "outputId": "f499f637-b83a-44e3-c026-6ffa34c14bc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm():\n",
        "    model = keras.Sequential([ layers.Embedding(max_features, 128, input_length=maxlen), layers.LSTM(64), layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",  metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Z7PhFdtNN9KT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_conv1d():\n",
        "    model = keras.Sequential([\n",
        "        layers.Embedding(max_features, 128, input_length=maxlen),\n",
        "        layers.Conv1D(64, 5, activation=\"relu\"),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(64, 5, activation=\"relu\"),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "v-hnDm0iN_EN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "# Train LSTM\n",
        "print(\"\\nTraining LSTM...\")\n",
        "lstm = build_lstm()\n",
        "lstm.fit(x_train, y_train,  batch_size=64, epochs=3,  validation_split=0.2, verbose=2)\n",
        "score = lstm.evaluate(x_test, y_test, verbose=0)\n",
        "results[\"LSTM\"] = score[1]\n",
        "\n",
        "# Train Conv1D\n",
        "print(\"\\nTraining Conv1D...\")\n",
        "conv = build_conv1d()\n",
        "conv.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2, verbose=2)\n",
        "score = conv.evaluate(x_test, y_test, verbose=0)\n",
        "results[\"Conv1D\"] = score[1]\n",
        "\n",
        "print(\"\\nFinal Test Accuracy Comparison:\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eHumLCQOBmx",
        "outputId": "7b99daab-de18-486e-a002-4b081c7fc9e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM...\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 - 86s - 761ms/step - accuracy: 0.4348 - loss: 2.3859 - val_accuracy: 0.4925 - val_loss: 2.0147\n",
            "Epoch 2/3\n",
            "113/113 - 79s - 696ms/step - accuracy: 0.4767 - loss: 2.0561 - val_accuracy: 0.2298 - val_loss: 2.2125\n",
            "Epoch 3/3\n",
            "113/113 - 81s - 720ms/step - accuracy: 0.5228 - loss: 1.8136 - val_accuracy: 0.5665 - val_loss: 1.7068\n",
            "\n",
            "Training Conv1D...\n",
            "Epoch 1/3\n",
            "113/113 - 37s - 324ms/step - accuracy: 0.4575 - loss: 2.2309 - val_accuracy: 0.5554 - val_loss: 1.7245\n",
            "Epoch 2/3\n",
            "113/113 - 34s - 304ms/step - accuracy: 0.6092 - loss: 1.5819 - val_accuracy: 0.6377 - val_loss: 1.4780\n",
            "Epoch 3/3\n",
            "113/113 - 41s - 364ms/step - accuracy: 0.7029 - loss: 1.2665 - val_accuracy: 0.6962 - val_loss: 1.3075\n",
            "\n",
            "Final Test Accuracy Comparison:\n",
            "LSTM: 0.5637\n",
            "Conv1D: 0.6803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3"
      ],
      "metadata": {
        "id": "ZmOCCno3T1yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
        "fname = keras.utils.get_file(\"jena_climate.csv.zip\", url, extract=True)\n",
        "\n",
        "# Construct the correct file path within the extracted directory\n",
        "fpath = os.path.join(os.path.dirname(fname), os.path.splitext(os.path.basename(fname))[0], \"jena_climate_2009_2016.csv\")\n",
        "\n",
        "# Load into dataframe\n",
        "df = pd.read_csv(fpath)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tnAwUNjT21O",
        "outputId": "17537e5d-2c7b-4ca8-8aa1-6a191a7f565b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
            "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
            "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
            "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
            "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
            "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
            "\n",
            "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
            "0          3.33          3.11          0.22       1.94             3.12   \n",
            "1          3.23          3.02          0.21       1.89             3.03   \n",
            "2          3.21          3.01          0.20       1.88             3.02   \n",
            "3          3.26          3.07          0.19       1.92             3.08   \n",
            "4          3.27          3.08          0.19       1.92             3.09   \n",
            "\n",
            "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
            "0       1307.75      1.03           1.75     152.3  \n",
            "1       1309.80      0.72           1.50     136.1  \n",
            "2       1310.24      0.19           0.63     171.6  \n",
            "3       1309.19      0.34           0.50     198.0  \n",
            "4       1309.00      0.32           0.63     214.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataframe to numpy (excluding the 'Date Time' column)\n",
        "data = df.iloc[:, 1:].values\n",
        "\n",
        "# Standardize (normalize)\n",
        "mean = data[:200000].mean(axis=0)\n",
        "std = data[:200000].std(axis=0)\n",
        "data = (data - mean) / std"
      ],
      "metadata": {
        "id": "SBTEWeU1T5SI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "lookback = 720     # how many past timesteps (10 min * 720 = 5 days)\n",
        "step = 6           # sample one data point every hour\n",
        "delay = 144        # predict 24 hours in the future\n",
        "batch_size = 128\n",
        "\n",
        "def generator(data, lookback, delay, min_index, max_index,\n",
        "              shuffle=False, batch_size=128, step=6):\n",
        "    if max_index is None:\n",
        "        max_index = len(data) - delay - 1\n",
        "    i = min_index + lookback\n",
        "    while True:\n",
        "        if shuffle:\n",
        "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
        "        else:\n",
        "            if i + batch_size >= max_index:\n",
        "                i = min_index + lookback\n",
        "            rows = np.arange(i, min(i + batch_size, max_index))\n",
        "            i += len(rows)\n",
        "\n",
        "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
        "        targets = np.zeros((len(rows),))\n",
        "        for j, row in enumerate(rows):\n",
        "            indices = range(rows[j] - lookback, rows[j], step)\n",
        "            samples[j] = data[indices]\n",
        "            targets[j] = data[rows[j] + delay][1]  # column 1 = temp in dataset\n",
        "        yield samples, targets\n"
      ],
      "metadata": {
        "id": "LhfI14VXT7Ir"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generator(data, lookback=lookback, delay=delay, min_index=0, max_index=200000, shuffle=True, step=step, batch_size=batch_size)\n",
        "\n",
        "val_gen = generator(data, lookback=lookback, delay=delay, min_index=200001, max_index=300000, step=step, batch_size=batch_size)\n",
        "\n",
        "test_gen = generator(data, lookback=lookback, delay=delay, min_index=300001, max_index=None, step=step, batch_size=batch_size)\n",
        "\n",
        "val_steps = (300000 - 200001 - lookback) // batch_size\n",
        "test_steps = (len(data) - 300001 - lookback) // batch_size\n"
      ],
      "metadata": {
        "id": "ajnXNPkgT9GD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([layers.LSTM(32, input_shape=(lookback // step, data.shape[-1])), layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mae\")\n"
      ],
      "metadata": {
        "id": "tGDmBL4fT_U-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_gen, steps_per_epoch=500, epochs=20, validation_data=val_gen, validation_steps=val_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoAcSpJqUBi5",
        "outputId": "e4e8d00d-49c9-42b6-d28f-2b7a656f98c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 118ms/step - loss: 0.3321 - val_loss: 0.2817\n",
            "Epoch 2/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 168ms/step - loss: 0.2791 - val_loss: 0.2697\n",
            "Epoch 3/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 157ms/step - loss: 0.2655 - val_loss: 0.2787\n",
            "Epoch 4/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 166ms/step - loss: 0.2551 - val_loss: 0.2824\n",
            "Epoch 5/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 107ms/step - loss: 0.2458 - val_loss: 0.2810\n",
            "Epoch 6/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 106ms/step - loss: 0.2404 - val_loss: 0.2852\n",
            "Epoch 7/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 164ms/step - loss: 0.2335 - val_loss: 0.2888\n",
            "Epoch 8/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 106ms/step - loss: 0.2298 - val_loss: 0.2909\n",
            "Epoch 9/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 106ms/step - loss: 0.2228 - val_loss: 0.2950\n",
            "Epoch 10/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 163ms/step - loss: 0.2196 - val_loss: 0.2983\n",
            "Epoch 11/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 108ms/step - loss: 0.2126 - val_loss: 0.2999\n",
            "Epoch 12/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 108ms/step - loss: 0.2106 - val_loss: 0.2953\n",
            "Epoch 13/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 107ms/step - loss: 0.2111 - val_loss: 0.3083\n",
            "Epoch 14/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 107ms/step - loss: 0.2055 - val_loss: 0.3073\n",
            "Epoch 15/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 107ms/step - loss: 0.2041 - val_loss: 0.3112\n",
            "Epoch 16/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 164ms/step - loss: 0.2008 - val_loss: 0.3082\n",
            "Epoch 17/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 164ms/step - loss: 0.1975 - val_loss: 0.3118\n",
            "Epoch 18/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 164ms/step - loss: 0.1940 - val_loss: 0.3124\n",
            "Epoch 19/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 163ms/step - loss: 0.1900 - val_loss: 0.3134\n",
            "Epoch 20/20\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 165ms/step - loss: 0.1886 - val_loss: 0.3147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = model.evaluate(test_gen, steps=test_steps)\n",
        "print(\"Test MAE:\", test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep6uZdb-UDX8",
        "outputId": "27b280a4-2b34-4ea0-93a7-91b627a05ea1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m936/936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 30ms/step - loss: 0.3295\n",
            "Test MAE: 0.32906925678253174\n"
          ]
        }
      ]
    }
  ]
}