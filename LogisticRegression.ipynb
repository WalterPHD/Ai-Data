{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAk6hhjUqYf9lH/lQL8hs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalterPHD/Ai-Data/blob/main/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scratch code"
      ],
      "metadata": {
        "id": "Rt1iK2xM8LK4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQkRldtdwdyJ"
      },
      "outputs": [],
      "source": [
        "class ScratchLogisticRegression():\n",
        "  def __init__(self, num_iter, lr, bias, verbose, lam):\n",
        "  self.num_iter = num_iter\n",
        "self.lr = lr\n",
        "self.bias = bias\n",
        "self.verbose = verbose\n",
        "self.lam = lam\n",
        "self.theta = np.array([])\n",
        "self.loss = np.array([])\n",
        "self.val_loss = np.array([])\n",
        "\n",
        "def fit(self, X_train, y_train, X_val = None, y_val = None):\n",
        "  \"\"\n",
        "\"train\"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def _gradient_descent(self, X, y):\n",
        "  \"\"\n",
        "\"Θ update (steepest descent method)\"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def _sigmoid(self, y):\n",
        "  \"\"\n",
        "\"sigmoidfunction\"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def _logistic_hypothesis(self, X):\n",
        "  \"\"\n",
        "\"Hypothetical function\"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def predict(self, X):\n",
        "  \"\"\n",
        "\"predict\"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def predict_proba(self, X):\n",
        "  \"\"\n",
        "\"probabilistic prediction \"\n",
        "\"\"\n",
        "pass\n",
        "\n",
        "def _loss_func(self, pred, y):\n",
        "  \"\"\n",
        "\"cross entropy error function\"\n",
        "\"\"\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Functions"
      ],
      "metadata": {
        "id": "0Vh14ryI89Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _sigmoid(self, y):\n",
        "    return 1 / (1 + np.exp(-y))\n",
        "\n",
        "\n",
        "def _logistic_hypothesis(self, X):\n",
        "    pred = X @ self.theta\n",
        "    pred = self._sigmoid(pred)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "0OjSEgOu85Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function with L2 regularization focus"
      ],
      "metadata": {
        "id": "kuZJdUdd9efp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _gradient_descent(self, X, y):\n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "    pred = self._logistic_hypothesis(X)\n",
        "    for j in range(n):\n",
        "        gradient = 0\n",
        "        for i in range(m):\n",
        "            gradient += (pred[i] - y[i]) * X[i, j]\n",
        "        self.theta[j] = self.theta[j] - self.lr * (\n",
        "            (gradient + self.lam * self.theta[j]) / m\n",
        "        )"
      ],
      "metadata": {
        "id": "NdbH6dcb9h3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "functionn for prediction"
      ],
      "metadata": {
        "id": "vOab2p2Q9x90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba(self, X):\n",
        "    if self.bias == True:\n",
        "        a = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
        "        X = np.hstack([a, X])\n",
        "    pred = self._logistic_hypothesis(X)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "7QDF-a6U937M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _loss_func(self, pred, y):\n",
        "    error = 0\n",
        "    for i in range(y.shape[0]):\n",
        "        error += -np.sum(y[i] * np.log(pred[i]) + (1 - y[i]) * np.log(1 - pred[i]))\n",
        "    loss = error / (y.shape[0])\n",
        "    loss = loss + np.sum(self.theta**2) * self.lam / (2 * y.shape[0])\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0hB86Tbb-Y3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualization"
      ],
      "metadata": {
        "id": "NsXs2UV0-9kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_region(X, y, slr):\n",
        "    mesh_f0, mesh_f1 = np.meshgrid(\n",
        "        np.arange(np.min(X[:, 0]), np.max(X[:, 0]), 0.01),\n",
        "        np.arange(np.min(X[:, 1]), np.max(X[:, 1]), 0.01),\n",
        "    )\n",
        "    mesh = np.c_[np.ravel(mesh_f0), np.ravel(mesh_f1)]\n",
        "    y_pred = slr.predict(mesh).reshape(mesh_f0.shape)\n",
        "    plt.title(\"decision region\")\n",
        "    plt.xlabel(\"feature0\")\n",
        "    plt.ylabel(\"feature1\")\n",
        "    plt.contourf(mesh_f0, mesh_f1, y_pred, cmap=ListedColormap([\"pink\", \"skyblue\"]))\n",
        "    plt.contour(mesh_f0, mesh_f1, y_pred, colors=\"red\")\n",
        "    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], label=\"0\")\n",
        "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label=\"1\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iuT3fHCu-_eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment Scratch Lositic Regression"
      ],
      "metadata": {
        "id": "P1GyYFNc_CIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1 Hypothetical Function"
      ],
      "metadata": {
        "id": "t8KJoZ7t_O3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please implement the method of logistic regression assumption function in ScratchLogisticRegression class.\n",
        "\n",
        "The assumed function for logistic regression is the assumed function for linear regression passed through the Sigmoid function. The sigmoid function is represented by the following equation\n",
        "\n",
        "g​ ​(z)​ ​=​ ​1​ ​1​ ​+​ ​e-zg(z)=11+e−z"
      ],
      "metadata": {
        "id": "4JodFvLLBvL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2 Steepest Decent"
      ],
      "metadata": {
        "id": "pOS73XdRB2zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the steepest descent method for learning. Add a method _gradient_descent that updates the parameters as shown in the following equation, and call it from the fit method."
      ],
      "metadata": {
        "id": "6H1O0fu2B5z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3 Estimated"
      ],
      "metadata": {
        "id": "0ye4snmKB9r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please implement the estimation mechanism. Add to the predict method and predict_proba method included in the template of ScratchLogisticRegression class.\n",
        "\n",
        "The output of the hypothetical function $h_\\theta(x)$ is the return value of predict_proba, and the return value of predict is a threshold value labeled 1 and 0."
      ],
      "metadata": {
        "id": "L8Y_qi3rCCG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4 Objective Function\n"
      ],
      "metadata": {
        "id": "aNniKHI3CFtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Objective function (loss function) of the logistic regression expressed in the following formula And make sure that this is recorded inself.loss, self.val_loss .\n",
        "\n"
      ],
      "metadata": {
        "id": "OAc8CmenCIbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5 Learning and Estimation"
      ],
      "metadata": {
        "id": "T4dJv0tSCOQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn and estimate the scratch implementation for the binary classification of virgicolor and virginica in the iris data set provided in the Introduction to Scratch Machine Learning Sprint.\n",
        "\n"
      ],
      "metadata": {
        "id": "DLQuMP4XCqao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 6 Plot of Learning Curve"
      ],
      "metadata": {
        "id": "IDjOdM0BCts5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the learning curve to see if the losses are falling properly."
      ],
      "metadata": {
        "id": "E2ZH5pRrCzUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 7 Visualization of Decision area"
      ],
      "metadata": {
        "id": "VTiW8U-4C3TB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the decision region. The following is a reference diagram. It is drawn with sepal width on the horizontal axis and petal length on the vertical axis."
      ],
      "metadata": {
        "id": "iZ-gIQx6C_QX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 8 Saving weights"
      ],
      "metadata": {
        "id": "pLRFMeCQDAEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s save and load the learned weights for easy verification. Use the pickle module and NumPy’s np.savez."
      ],
      "metadata": {
        "id": "LEHH4jJzDFz-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPZMedh6DHwO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}