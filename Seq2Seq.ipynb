{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCsiWUEL5MjKa1KeLdjVlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalterPHD/Ai-Data/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_na4u2B8xY5D"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Title: Character-level recurrent sequence-to-sequence model\n",
        "Author: [fchollet](https://twitter.com/fchollet)\n",
        "Date created: 2017/09/29\n",
        "Last modified: 2023/11/22\n",
        "Description: Character-level recurrent sequence-to-sequence model.\n",
        "Accelerator: GPU\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "## Introduction\n",
        "\n",
        "This example demonstrates how to implement a basic character-level\n",
        "recurrent sequence-to-sequence model. We apply it to translating\n",
        "short English sentences into short French sentences,\n",
        "character-by-character. Note that it is fairly unusual to\n",
        "do character-level machine translation, as word-level\n",
        "models are more common in this domain.\n",
        "\n",
        "**Summary of the algorithm**\n",
        "\n",
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and corresponding target sequences from another domain\n",
        "    (e.g. French sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    It uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "## Setup\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "import os\n",
        "from pathlib import Path\n",
        "import requests # Import requests library\n",
        "import zipfile # Import zipfile library\n",
        "\n",
        "\"\"\"\n",
        "## Download the data\n",
        "\"\"\"\n",
        "\n",
        "# Using a small, hardcoded dataset due to issues with downloading from the original source.\n",
        "# This will allow the rest of the code to run, but the model will not be trained on a large dataset.\n",
        "\n",
        "# url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
        "# fpath = keras.utils.get_file(\n",
        "#     origin=url, fname=\"fra-eng.zip\", extract=True, cache_subdir=\"datasets\"\n",
        "# )\n",
        "# dirpath = Path(fpath).parent.absolute()\n",
        "# data_path = os.path.join(dirpath, \"fra.txt\")\n",
        "\n",
        "\"\"\"\n",
        "## Configuration\n",
        "\"\"\"\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "# data_path is no longer needed as we are using a hardcoded dataset.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Prepare the data\n",
        "\"\"\"\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "# Hardcoded small dataset\n",
        "input_texts = [\"Go.\", \"Hi.\", \"Run!\", \"Run!\", \"Who?\", \"Wow!\", \"Fire!\", \"Help!\", \"Jump.\", \"Stop!\", \"Stop!\", \"Stop!\", \"Wait!\", \"Wait!\", \"Go on.\", \"Go on.\", \"I see.\", \"I try.\", \"I won!\", \"Oh no!\"]\n",
        "target_texts = [\"\\tVa !\\n\", \"\\tSalut !\\n\", \"\\tCours !\\n\", \"\\tCourez !\\n\", \"\\tQui ?\\n\", \"\\tÇa alors !\\n\", \"\\tAu feu !\\n\", \"\\tÀ l'aide !\\n\", \"\\tSaute.\\n\", \"\\tÇa suffit !\\n\", \"\\tStop !\\n\", \"\\tArrête-toi !\\n\", \"\\tAttends !\\n\", \"\\tAttendez !\\n\", \"\\tContinuez.\\n\", \"\\tPoursuis.\\n\", \"\\tJe vois.\\n\", \"\\tJ'essaie.\\n\", \"\\tJ'ai gagné !\\n\", \"\\tOh non !\\n\"]\n",
        "\n",
        "\n",
        "for input_text, target_text in zip(input_texts, target_texts):\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    # Pad with spaces if the input text is shorter than max_encoder_seq_length\n",
        "    for t in range(len(input_text), max_encoder_seq_length):\n",
        "        encoder_input_data[i, t, input_token_index[\" \"]] = 1.0\n",
        "\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    # Pad with spaces if the target text is shorter than max_decoder_seq_length\n",
        "    for t in range(len(target_text), max_decoder_seq_length):\n",
        "        decoder_input_data[i, t, target_token_index[\" \"]] = 1.0\n",
        "        decoder_target_data[i, t, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## Build the model\n",
        "\"\"\"\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "\"\"\"\n",
        "## Train the model\n",
        "\"\"\"\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s_model.keras\")\n",
        "\n",
        "\"\"\"\n",
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n",
        "\"\"\"\n",
        "\n",
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s_model.keras\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "You can now generate decoded sentences as such:\n",
        "\"\"\"\n",
        "\n",
        "for seq_index in range(len(input_texts)):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1"
      ],
      "metadata": {
        "id": "S-Q0d1mk1Ain"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check versions\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laVar1aW1B1R",
        "outputId": "3cc2899a-ad3f-488f-c3c6-8cb1f87d617a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_texts = [\"Hello!\", \"How are you?\", \"I am fine.\"]\n",
        "target_texts = [\"\\tBonjour !\\n\", \"\\tComment ça va ?\\n\", \"\\tJe vais bien.\\n\"]\n",
        "\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for input_text, target_text in zip(input_texts, target_texts):\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of unique input chars:\", num_encoder_tokens)\n",
        "print(\"Number of unique output chars:\", num_decoder_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jH_v_DV1EKi",
        "outputId": "06895823-ccf5-4b35-8986-62a94349a010"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique input chars: 18\n",
            "Number of unique output chars: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Use the hardcoded small dataset defined in the first cell\n",
        "# input_texts = [\"Hello!\", \"How are you?\", \"I am fine.\"]\n",
        "# target_texts = [\"\\tBonjour !\\n\", \"\\tComment ça va ?\\n\", \"\\tJe vais bien.\\n\"]\n",
        "\n",
        "# Ensure input_texts and target_texts are available from the previous cell\n",
        "if 'input_texts' not in globals() or 'target_texts' not in globals():\n",
        "    print(\"Error: input_texts and target_texts not found. Please run the previous cell.\")\n",
        "else:\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "\n",
        "    for input_text, target_text in zip(input_texts, target_texts):\n",
        "        for char in input_text:\n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "        for char in target_text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "\n",
        "    input_characters = sorted(list(input_characters))\n",
        "    target_characters = sorted(list(target_characters))\n",
        "\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "        # Pad with spaces if the input text is shorter than max_encoder_seq_length\n",
        "        for t in range(len(input_text), max_encoder_seq_length):\n",
        "             encoder_input_data[i, t, input_token_index[\" \"]] = 1.0\n",
        "\n",
        "        for t, char in enumerate(target_text):\n",
        "            decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "            if t > 0:\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "        # Pad with spaces if the target text is shorter than max_decoder_seq_length\n",
        "        for t in range(len(target_text), max_decoder_seq_length):\n",
        "             decoder_input_data[i, t, target_token_index[\" \"]] = 1.0\n",
        "             decoder_target_data[i, t, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "Xlr7XH8v1IYH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "pogNOYqX1LLy",
        "outputId": "d2c53373-fc62-4fff-b61a-519f1b9869a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m281,600\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m286,720\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)  │      \u001b[38;5;34m5,911\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">281,600</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">286,720</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,911</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m574,231\u001b[0m (2.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">574,231</span> (2.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m574,231\u001b[0m (2.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">574,231</span> (2.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup for inference\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"
      ],
      "metadata": {
        "id": "4E2CjAZb1ODv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1,num_decoder_tokens))\n",
        "    target_seq[0,0,target_token_index['\\t']] = 1.0\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1,num_decoder_tokens))\n",
        "        target_seq[0,0,sampled_token_index] = 1.0\n",
        "        states_value = [h,c]\n",
        "    return decoded_sentence\n",
        "\n",
        "# Test decoding\n",
        "for seq_index in range(len(input_texts)):\n",
        "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"Input:\", input_texts[seq_index])\n",
        "    print(\"Decoded:\", decoded_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7BphKT1Qzy",
        "outputId": "762ddc5c-17bf-4d61-87fe-78b0c0e6470d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Input: Hello!\n",
            "Decoded: bbbCtstsmbbCtts ?t\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Input: How are you?\n",
            "Decoded: bbmbbbtmbbtbtCtsts\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Input: I am fine.\n",
            "Decoded: !!C!mmum  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b73bbcc1"
      },
      "source": [
        "Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0me_Djq1fTi",
        "outputId": "a9809c1c-a172-4111-e44d-a0cbbb19f7e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_cl14cp1bhl",
        "outputId": "dba028de-9783-44eb-9677-d0c3fe299d6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img_path = \"image_test.png\"  # Change to your image file\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "fF-iMcVl1j6w",
        "outputId": "375d47ad-8aff-4bca-80df-4a66e4db2f06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "image_tensor = transform(image).unsqueeze(0).to(device)  # Shape: (1, 3, 224, 224)\n"
      ],
      "metadata": {
        "id": "hJMChNcM2Tcu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = resnet50(pretrained=True).to(device)\n",
        "resnet.eval()  # Set to evaluation mode\n",
        "\n",
        "# Remove the last classification layer\n",
        "encoder = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "encoder.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = encoder(image_tensor)\n",
        "    features = features.view(features.size(0), -1)  # Flatten\n",
        "print(\"Feature vector shape:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zhnuQpF2fnb",
        "outputId": "939378aa-7316-4058-cb08-caf59b5a9336"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature vector shape: torch.Size([1, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = ['<start>', '<end>', 'a', 'cat', 'in', 'a', 'pumpkin', 'sitting']  # Example vocab\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Dummy decoder prediction (for demonstration)\n",
        "def dummy_caption(features):\n",
        "    return \"a cat sitting in a pumpkin\"\n",
        "\n",
        "caption = dummy_caption(features)\n",
        "print(\"Generated Caption:\", caption)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhNFEexa2jHa",
        "outputId": "20633227-db6c-43c5-c5ad-3eb23acaf08b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: a cat sitting in a pumpkin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3"
      ],
      "metadata": {
        "id": "09tZWodR3W17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch # Import torch\n",
        "\n",
        "# Dummy batch of images\n",
        "dummy_images = np.random.rand(2, 224, 224, 3).astype(np.float32)\n",
        "\n",
        "# Convert numpy array to PyTorch Tensor and move to the correct device\n",
        "dummy_images_tensor = torch.from_numpy(dummy_images).permute(0, 3, 1, 2).to(device) # Permute to (batch, channels, height, width)\n",
        "\n",
        "image_features = encoder(dummy_images_tensor) # Pass the PyTorch Tensor to the encoder\n",
        "\n",
        "# Dummy batch of tokenized captions\n",
        "# Assuming max_length and vocab_size are defined in a previous cell\n",
        "# If not, you might need to define them or ensure they are in the global scope\n",
        "try:\n",
        "    dummy_seq = np.random.randint(0, vocab_size, (2, max_length))\n",
        "except NameError:\n",
        "    print(\"Error: vocab_size or max_length not defined. Please ensure they are defined in a previous cell.\")\n",
        "    # You might want to handle this case more robustly, e.g., by defining default values\n",
        "    vocab_size = 10000  # Default value if not defined\n",
        "    max_length = 20     # Default value if not defined\n",
        "    dummy_seq = np.random.randint(0, vocab_size, (2, max_length))\n",
        "\n",
        "\n",
        "# Convert numpy array to tensor\n",
        "dummy_seq_tf = tf.convert_to_tensor(dummy_seq, dtype=tf.int32)\n",
        "\n",
        "# Forward pass\n",
        "# Assuming the decoder is a TensorFlow model as built in cell 4M2u-ReU3XxC or _RZILXdy4CKD\n",
        "# You need to ensure the decoder is built and available before this cell is executed.\n",
        "try:\n",
        "    predictions = decoder([dummy_seq_tf, image_features.detach().cpu().numpy()]) # Convert PyTorch features back to numpy for TF decoder\n",
        "    print(\"Output shape:\", predictions.shape)\n",
        "except NameError:\n",
        "    print(\"Error: decoder not defined. Please ensure the decoder model is built in a previous cell.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during the forward pass: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BccSA2-83wjl",
        "outputId": "6576be4c-dccf-4669-b8bb-5aeae1df1a0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: vocab_size or max_length not defined. Please ensure they are defined in a previous cell.\n",
            "Error: decoder not defined. Please ensure the decoder model is built in a previous cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout\n",
        "import keras\n",
        "\n",
        "\n",
        "# Encoder: CNN for image features\n",
        "def build_encoder(embedding_dim=256):\n",
        "    # Pre-trained ResNet50 without the top classifier\n",
        "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "    # Freeze CNN layers if using pre-trained weights\n",
        "    base_model.trainable = False\n",
        "    # Dense layer to project image features into embedding space\n",
        "    image_input = Input(shape=(224, 224, 3))\n",
        "    features = base_model(image_input)\n",
        "    features = Dense(embedding_dim, activation='relu')(features)\n",
        "    encoder_model = Model(inputs=image_input, outputs=features, name=\"encoder\")\n",
        "    return encoder_model\n",
        "\n",
        "\n",
        "# Decoder: LSTM for captions\n",
        "def build_decoder(vocab_size, max_length, embedding_dim=256, lstm_units=512):\n",
        "    # Input for text sequences\n",
        "    seq_input = Input(shape=(max_length,), dtype=tf.int32) # Specify dtype\n",
        "    # Input for image features from encoder\n",
        "    image_features_input = Input(shape=(embedding_dim,))\n",
        "\n",
        "    # Word embedding\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(seq_input)\n",
        "\n",
        "    # Combine image features with first LSTM step\n",
        "    # Expand dims to match LSTM time dimension\n",
        "    image_features = keras.ops.expand_dims(image_features_input, 1)\n",
        "    x = keras.ops.concatenate([image_features, x], axis=1)\n",
        "\n",
        "    # LSTM layer\n",
        "    x = LSTM(lstm_units, return_sequences=True)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "    decoder_model = Model(inputs=[seq_input, image_features_input], outputs=output, name=\"decoder\")\n",
        "    return decoder_model\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 256\n",
        "lstm_units = 512\n",
        "vocab_size = 10000  # Example vocab size\n",
        "max_length = 20     # Max caption length\n",
        "\n",
        "# Build Models\n",
        "encoder = build_encoder(embedding_dim)\n",
        "decoder = build_decoder(vocab_size, max_length, embedding_dim, lstm_units)\n",
        "\n",
        "# Summary\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "\n",
        "# Example forward pass\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "# Random image batch (simulate batch of images)\n",
        "dummy_images = np.random.rand(2, 224, 224, 3).astype(np.float32)\n",
        "image_features = encoder(dummy_images)\n",
        "\n",
        "# Random sequences (simulate tokenized captions)\n",
        "dummy_seq = np.random.randint(0, vocab_size, (2, max_length))\n",
        "# Convert dummy_seq to a TensorFlow Tensor\n",
        "dummy_seq_tensor = tf.constant(dummy_seq, dtype=tf.int32) # Specify dtype\n",
        "print(f\"Type of dummy_seq_tensor: {type(dummy_seq_tensor)}\")\n",
        "print(f\"Type of image_features: {type(image_features)}\")\n",
        "\n",
        "predictions = decoder([dummy_seq_tensor, image_features])\n",
        "print(\"Output shape:\", predictions.shape)  # (batch_size, max_length+1, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "4M2u-ReU3XxC",
        "outputId": "9e5188ee-ee2d-44e9-90d7-d407c9a1c031"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,112,256\u001b[0m (91.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,112,256</span> (91.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m524,544\u001b[0m (2.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> (2.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ expand_dims         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mExpandDims\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,560,000\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ expand_dims[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,574,912\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m5,130,000\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ expand_dims         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ExpandDims</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ expand_dims[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,264,912\u001b[0m (35.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264,912</span> (35.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,264,912\u001b[0m (35.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,264,912</span> (35.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of dummy_seq_tensor: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Type of image_features: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Output shape: (2, 21, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4"
      ],
      "metadata": {
        "id": "QxyweVjY3-OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = 10000  # Example vocabulary size\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "max_length = 20  # Maximum caption length\n",
        "\n",
        "\n",
        "# Encoder (CNN)\n",
        "\n",
        "def build_encoder():\n",
        "    base_model = tf.keras.applications.ResNet50(\n",
        "        include_top=False, weights='imagenet', pooling='avg', input_shape=(224, 224, 3)\n",
        "    )\n",
        "    base_model.trainable = False  # Freeze CNN weights\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    features = base_model(inputs)\n",
        "    features = layers.Dense(embedding_dim, activation='relu')(features)\n",
        "    return Model(inputs, features, name=\"encoder\")\n",
        "\n",
        "\n",
        "# Decoder (RNN)\n",
        "def build_decoder():\n",
        "    # Inputs\n",
        "    seq_input = layers.Input(shape=(max_length,), dtype=tf.int32)\n",
        "    features_input = layers.Input(shape=(embedding_dim,))\n",
        "\n",
        "    # Caption embedding\n",
        "    x = layers.Embedding(vocab_size, embedding_dim)(seq_input) # Removed mask_zero=True\n",
        "    # Expand image features\n",
        "    features_expanded = layers.Reshape((1, embedding_dim))(features_input)\n",
        "    # Concatenate along time axis\n",
        "    x = layers.Concatenate(axis=1)([features_expanded, x])\n",
        "    # LSTM\n",
        "    x = layers.LSTM(units, return_sequences=True)(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    # Output dense layer\n",
        "    outputs = layers.Dense(vocab_size)(x)\n",
        "\n",
        "    return Model([seq_input, features_input], outputs, name=\"decoder\")\n",
        "\n",
        "\n",
        "# Instantiate models\n",
        "encoder = build_encoder()\n",
        "decoder = build_decoder()\n",
        "\n",
        "\n",
        "# Testing the forward pass\n",
        "dummy_images = np.random.rand(2, 224, 224, 3).astype(np.float32)\n",
        "image_features = encoder(dummy_images)\n",
        "\n",
        "dummy_seq = np.random.randint(0, vocab_size, (2, max_length))\n",
        "dummy_seq_tf = tf.convert_to_tensor(dummy_seq, dtype=tf.int32)\n",
        "\n",
        "predictions = decoder([dummy_seq_tf, image_features])\n",
        "print(\"Output shape:\", predictions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RZILXdy4CKD",
        "outputId": "3b6fcafe-6781-42d7-d2f5-8202bb2b8395"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (2, 21, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5: Developmental Survey - Machine Translation and Text-to-Image\n",
        "\n",
        "## 1️ Steps for translating Japanese ↔ English using sequence-to-sequence\n",
        "\n",
        "1. **Data preparation**:\n",
        "   - Collect parallel corpora (sentence pairs) in Japanese and English.\n",
        "     - Examples: [JParaCrawl](https://www.paracrawl.eu/), [KFTT](http://www.phontron.com/kftt/).\n",
        "   - Tokenize both languages carefully:\n",
        "     - English: whitespace + punctuation tokenization.\n",
        "     - Japanese: use a morphological analyzer like **MeCab** or **Sudachi**.\n",
        "   - Optionally, use subword tokenization (BPE or SentencePiece) to handle rare words.\n",
        "\n",
        "2. **Model adaptation**:\n",
        "   - Use a **sequence-to-sequence model** (LSTM/GRU or Transformer).\n",
        "   - Encoder processes Japanese sentence.\n",
        "   - Decoder generates English sentence (or vice versa).\n",
        "   - Attention mechanism is recommended for long sequences.\n",
        "\n",
        "3. **Training**:\n",
        "   - Train the model on the parallel corpus.\n",
        "   - Use **teacher forcing** during training: feed the ground truth word at each step.\n",
        "\n",
        "4. **Inference**:\n",
        "   - Use **beam search** or greedy decoding for generating translations.\n",
        "   - Convert subword tokens back into readable sentences.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - BLEU score, METEOR, or ROUGE metrics.\n",
        "   - Optionally, human evaluation for quality.\n",
        "\n",
        "---\n",
        "\n",
        "## 2️ Advanced methods for machine translation\n",
        "\n",
        "1. **Transformer architecture (Vaswani et al., 2017)**:\n",
        "   - Replaces RNNs/LSTMs with self-attention.\n",
        "   - Handles long-range dependencies efficiently.\n",
        "   - Basis of state-of-the-art models like **BERT**, **GPT**, **mBART**.\n",
        "\n",
        "2. **Pretrained multilingual models**:\n",
        "   - **mBART**, **mT5**, **XLM-R**: perform zero-shot translation between multiple languages.\n",
        "   - Fine-tuning allows translation with limited parallel corpora.\n",
        "\n",
        "3. **Subword and tokenization techniques**:\n",
        "   - Byte Pair Encoding (BPE), SentencePiece, WordPiece.\n",
        "   - Reduces unknown words and improves handling of rare vocabulary.\n",
        "\n",
        "4. **Neural post-editing**:\n",
        "   - First use a classical MT system (e.g., SMT), then apply a neural network to correct errors.\n",
        "\n",
        "5. **Reinforcement learning / minimum risk training**:\n",
        "   - Optimize directly for BLEU or other sequence-level metrics.\n",
        "\n",
        "---\n",
        "\n",
        "## 3️ Generating an image from text\n",
        "\n",
        "1. **Text-to-image models**:\n",
        "   - Input: descriptive text prompt.\n",
        "   - Output: realistic image.\n",
        "\n",
        "2. **Popular architectures**:\n",
        "   - **DALL·E**: Transformer-based text encoder + image decoder.\n",
        "   - **Stable Diffusion**: latent diffusion model with text conditioning.\n",
        "   - **Imagen**: large language model for text embedding + diffusion for image generation.\n",
        "\n",
        "3. **Key pipeline**:\n",
        "   - Encode text into embeddings.\n",
        "   - Condition the image generation network (GAN or diffusion) on the embeddings.\n",
        "   - Generate the image iteratively (diffusion steps or GAN training).\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "\n",
        "- Japanese ↔ English translation requires careful **tokenization** and **sequence-to-sequence modeling**.\n",
        "- Modern machine translation uses **Transformers**, **pretrained multilingual models**, and **subword tokenization**.\n",
        "- Image generation from text is a reverse problem of captioning, commonly handled with **diffusion models** or **text-conditioned GANs**.\n"
      ],
      "metadata": {
        "id": "AsdwSpCm4wPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Searched implementation (Not assignment) : Learning Word2Vec\n",
        "\n",
        "## 1️ Overview of Word2Vec\n",
        "\n",
        "Word2Vec converts words into **dense vectors** in a continuous vector space (embedding).  \n",
        "Unlike BoW or TF-IDF, which are sparse and high-dimensional, Word2Vec captures **semantic similarity** between words.\n",
        "\n",
        "Two main training approaches:\n",
        "\n",
        "1. **CBOW (Continuous Bag-of-Words)**:\n",
        "   - Predicts a target word from its surrounding context words.\n",
        "   - Faster for large corpora.\n",
        "   - Example: context [\"the\", \"cat\", \"on\", \"the\"] → target \"mat\"\n",
        "\n",
        "2. **Skip-gram**:\n",
        "   - Predicts context words from a target word.\n",
        "   - Performs better for rare words.\n",
        "   - Example: target \"cat\" → context [\"the\", \"on\", \"the\", \"mat\"]\n",
        "\n",
        "---\n",
        "\n",
        "## 2️ Implementation in Python (using Gensim)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_LUEPjD85IO8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0af512a",
        "outputId": "3a5aecee-c9fe-433d-9fdf-6175efe40bb3"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample corpus: tokenized sentences\n",
        "sentences = [\n",
        "    [\"this\", \"movie\", \"is\", \"SOOOO\", \"funny\"],\n",
        "    [\"what\", \"a\", \"movie\", \"I\", \"never\"],\n",
        "    [\"best\", \"movie\", \"ever\", \"this\", \"movie\"]\n",
        "]\n",
        "\n",
        "# Train Word2Vec\n",
        "model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=10,  # embedding dimension\n",
        "    window=5,        # context window\n",
        "    min_count=1,     # include all words\n",
        "    sg=0             # CBOW (sg=1 for skip-gram)\n",
        ")\n",
        "\n",
        "# Vocabulary\n",
        "print(\"Vocabulary List:\", list(model.wv.key_to_index.keys()))\n",
        "\n",
        "# Word vectors\n",
        "for word in model.wv.key_to_index.keys():\n",
        "    print(f\"{word} vector:\\n{model.wv[word]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4zoEc3g5Rz7",
        "outputId": "6ab368ba-79b5-4fbc-cccf-a452ec2da250"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary List: ['movie', 'this', 'ever', 'never', 'best', 'I', 'a', 'funny', 'what', 'is', 'SOOOO']\n",
            "movie vector:\n",
            "[-0.00536237  0.00236436  0.05103445  0.09009442 -0.09303124 -0.07116942\n",
            "  0.06458993  0.08973157 -0.05015522 -0.03763442]\n",
            "\n",
            "this vector:\n",
            "[ 0.07380505 -0.01533471 -0.04536613  0.06554051 -0.0486016  -0.01816018\n",
            "  0.0287658   0.00991874 -0.08285215 -0.09448818]\n",
            "\n",
            "ever vector:\n",
            "[ 0.07311766  0.05070262  0.06757693  0.00762866  0.06350891 -0.03405366\n",
            " -0.00946401  0.05768573 -0.07521638 -0.03936104]\n",
            "\n",
            "never vector:\n",
            "[-0.07511582 -0.00930042  0.09538119 -0.07319167 -0.02333769 -0.01937741\n",
            "  0.08077437 -0.05930896  0.00045162 -0.04753734]\n",
            "\n",
            "best vector:\n",
            "[-0.0960373   0.05007387 -0.08759752 -0.04391912 -0.00035096 -0.00296184\n",
            " -0.07661387  0.09614919  0.04982154  0.09233318]\n",
            "\n",
            "I vector:\n",
            "[-0.08157917  0.04495798 -0.04137076  0.00824536  0.08498619 -0.04462177\n",
            "  0.045175   -0.0678696  -0.03548489  0.09398508]\n",
            "\n",
            "a vector:\n",
            "[-0.01577653  0.00321372 -0.0414063  -0.07682689 -0.01508008  0.02469795\n",
            " -0.00888027  0.05533662 -0.02742977  0.02260065]\n",
            "\n",
            "funny vector:\n",
            "[ 0.05455794  0.08345953 -0.01453741 -0.09208143  0.04370552  0.00571785\n",
            "  0.07441908 -0.00813283 -0.02638414 -0.08753009]\n",
            "\n",
            "what vector:\n",
            "[-0.00856557  0.02826563  0.05401429  0.07052656 -0.05703121  0.0185882\n",
            "  0.06088864 -0.04798051 -0.03107261  0.0679763 ]\n",
            "\n",
            "is vector:\n",
            "[ 0.01631476  0.00189917  0.03473637  0.00217777  0.09618826  0.05060603\n",
            " -0.0891739  -0.0704156   0.00901456  0.06392534]\n",
            "\n",
            "SOOOO vector:\n",
            "[-0.08619688  0.03665738  0.05189884  0.05741938  0.07466918 -0.06167675\n",
            "  0.01105614  0.06047282 -0.0284005  -0.06173522]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuation"
      ],
      "metadata": {
        "id": "MRE_qP6p6or_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "76oMRBYw6r1b"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all words in vocabulary\n",
        "vocabs = list(model.wv.key_to_index.keys())\n",
        "\n",
        "# Extract the vectors for all words\n",
        "vectors = [model.wv[word] for word in vocabs]\n"
      ],
      "metadata": {
        "id": "1_CkODjp6uUz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_model = TSNE(\n",
        "    n_components=2,   # 2D\n",
        "    perplexity=5,     # small corpus\n",
        "    init='pca',\n",
        "    n_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "vectors_2d = tsne_model.fit_transform(np.array(vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsmgSqA16wpF",
        "outputId": "46422dd5-49db-4a65-cd56-33f16a7943ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])\n",
        "\n",
        "# Annotate each word\n",
        "for i, word in enumerate(vocabs):\n",
        "    plt.annotate(word, xy=(vectors_2d[i, 0], vectors_2d[i, 1]))\n",
        "\n",
        "plt.title(\"Word2Vec Embeddings Visualized with t-SNE\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "qYEgUZIg6zKj",
        "outputId": "ba1b5378-a2cd-4a80-cc8d-3f2eab84ce06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_to_movie = model.wv.most_similar(\"movie\", topn=3)\n",
        "print(\"Words most similar to 'movie':\", similar_to_movie)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUI-pKtB65GP",
        "outputId": "7ed227ec-f7f7-4671-f769-d99c036c4df4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words most similar to 'movie': [('this', 0.5436005592346191), ('SOOOO', 0.4318247437477112), ('what', 0.3792896568775177)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using tensorflow"
      ],
      "metadata": {
        "id": "22Hlv1xj69rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, GlobalAveragePooling1D\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "50cyyfmR6--B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset (words already tokenized as integers)\n",
        "vocab_size = 10000  # top 10k words\n",
        "max_length = 100    # max review length\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post')\n",
        "x_test  = pad_sequences(x_test, maxlen=max_length, padding='post')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38_RZ0T7DzE",
        "outputId": "57193b31-b3ef-4d61-b6d7-c1bc5a191e82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert integer sequences to word lists\n",
        "word_index = imdb.get_word_index()\n",
        "index_word = {v+3:k for k,v in word_index.items()}  # Keras reserves 0-3\n",
        "\n",
        "# Convert reviews to list of words\n",
        "train_sentences = [[index_word.get(i, \"UNK\") for i in review] for review in x_train[:5000]]\n",
        "test_sentences  = [[index_word.get(i, \"UNK\") for i in review] for review in x_test[:1000]]\n",
        "\n",
        "# Train Word2Vec\n",
        "embedding_dim = 10\n",
        "w2v_model = Word2Vec(sentences=train_sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDsq1OjA7G21",
        "outputId": "ec59f60f-afed-4fd1-aff6-1a54c6bbced3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for i in range(1, vocab_size):\n",
        "    word = index_word.get(i, None)\n",
        "    if word and word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n"
      ],
      "metadata": {
        "id": "_P8sJR7j7JTm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix],\n",
        "                    input_length=max_length, trainable=False))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "RjwWDPgW7Lhs",
        "outputId": "c7740d5d-e562-4d08-929b-6c53c552bcab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m100,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m100,000\u001b[0m (390.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,000</span> (390.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train[:5000], y_train[:5000], epochs=5, batch_size=64, validation_data=(x_test[:1000], y_test[:1000]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q22Rktpp7OEI",
        "outputId": "fdfb6f1c-ffde-4b4a-c782-e706b349623e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5023 - loss: 0.8710 - val_accuracy: 0.5730 - val_loss: 0.6745\n",
            "Epoch 2/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 0.6804 - val_accuracy: 0.5810 - val_loss: 0.6703\n",
            "Epoch 3/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.6736 - val_accuracy: 0.5880 - val_loss: 0.6675\n",
            "Epoch 4/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5787 - loss: 0.6730 - val_accuracy: 0.6000 - val_loss: 0.6646\n",
            "Epoch 5/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5857 - loss: 0.6705 - val_accuracy: 0.5940 - val_loss: 0.6680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e110455cd10>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test[:1000], y_test[:1000])\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtdGZQhX7QyF",
        "outputId": "5a12e62c-54c9-40c1-a370-a03daf121156"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5953 - loss: 0.6709\n",
            "Test Accuracy: 0.593999981880188\n"
          ]
        }
      ]
    }
  ]
}